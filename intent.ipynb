{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import EnumOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manoj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "# nlp_pipeline = pipeline(\"text2text-generation\", model=model_name)\n",
    "\n",
    "# # Wrap the pipeline with HuggingFacePipeline\n",
    "# llm = HuggingFacePipeline(pipeline=nlp_pipeline)\n",
    "llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":1,\"max_length\":65})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"email_content\"],\n",
    "    template=\"\"\"\n",
    "    You are an AI trained to understand the intention of emails. Given the content of the email below, identify the intention as one of the following: [completed, pending, query].\n",
    "    \n",
    "    Email content:\n",
    "    {email_content}\n",
    "    \n",
    "    What is the intention of this email? Respond with one word: completed, pending, or query.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentOutputParser(StrOutputParser):\n",
    "    def parse(self, text: str) -> str:\n",
    "        # Simplified output parsing, assuming the model response will be one of the three words directly\n",
    "        text = text.strip().lower()\n",
    "        if text in [\"completed\", \"pending\", \"query\"]:\n",
    "            return text\n",
    "        return \"unknown\"\n",
    "    \n",
    "output_parser = IntentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain =LLMChain(llm=llm,prompt=prompt_template,output_parser=output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_intent(email_content: str) -> str:\n",
    "    # Generate the prompt and parse the output\n",
    "    response = llm_chain.invoke({\"email_content\": email_content})\n",
    "    intent = output_parser.parse(response)\n",
    "    return intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_content_pending = \"\"\"\n",
    "Hi team,\n",
    "\n",
    "I wanted to follow up on the status of the report that was supposed to be submitted last week. Has it been completed? If not, when can we expect it to be done?\n",
    "\n",
    "Thanks,\n",
    "John\n",
    "\"\"\"\n",
    "\n",
    "email_content_completed = \"\"\"\n",
    "Hi team,\n",
    "\n",
    "Great news! The report that was due last week has been completed and submitted successfully. Thank you all for your hard work and dedication to getting this done on time.\n",
    "\n",
    "Best regards,\n",
    "John\n",
    "\"\"\"\n",
    "\n",
    "email_content_query = \"\"\"\n",
    "Hi team,\n",
    "\n",
    "I have a question regarding the data analysis project. Can someone clarify the steps we need to follow to merge the datasets? I am also unsure about the deadline for the preliminary findings. Could someone provide more details on this?\n",
    "\n",
    "Thanks,\n",
    "John\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = llm_chain.run(email_content_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
